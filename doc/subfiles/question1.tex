% !TeX root = ../main.tex
\documentclass[class=article]{standalone}
\usepackage{listings}
\usepackage{amsthm}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Environnement deriv pour les dérivations
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\newlength{\indentationFormule}
\setlength{\indentationFormule}{1.3em}
\newlength{\indentationTotaleFormule}
\newlength{\indentationCommentaire}
\setlength{\indentationCommentaire}{4em}
\newlength{\indentationDerivation}
\newlength{\largeurLangle}
\settowidth{\largeurLangle}{$\langle$\hspace*{.4em}}
\newlength{\largeurBoiteCommentaire}

\newenvironment{deriv}[1][\leftmargini]%
  {\setlength{\indentationDerivation}{#1}%
    \setlength{\indentationTotaleFormule}{\indentationFormule}
    \addtolength{\indentationTotaleFormule}{#1}
    \setlength{\largeurBoiteCommentaire}{\linewidth}
    \addtolength{\largeurBoiteCommentaire}{-\indentationFormule}
    \addtolength{\largeurBoiteCommentaire}{-\indentationCommentaire}
    \addtolength{\largeurBoiteCommentaire}{-\largeurLangle}
    \addtolength{\largeurBoiteCommentaire}{-\indentationDerivation}
    \begin{list}{}{\setlength{\leftmargin}{\indentationTotaleFormule}}
                   \setlength{\baselineskip}{1.3\baselineskip}
                   \item$}%
   {\hbox{}$\end{list}}  % \hbox{} évite des underfull lors d'usages
                         % sans \< et sans \commentaire (et avec
                         % des \\ pour changer de ligne).

\newcommand{\<}[1]{\\\hspace*{-\indentationFormule}\makebox(0,0)[bl]{$#1$}\hspace*{\indentationFormule}}

\newcommand{\commentaire}[1]{\hspace*{\indentationCommentaire}\langle\hspace*{.4em}%
    \begin{minipage}[t]{\largeurBoiteCommentaire}%
        #1 $\rangle$\\\hbox{}% Bizarre. Pourquoi ça prend \\ ici et aussi à la ligne suivante ?
                           % Sans \hbox{}, il y a des underfull.
    \end{minipage}\\[-1ex] % Sans ces deux \\, l'espace après un commentaire n'est pas le même quand
                           % le commentaire a plus d'une ligne.
}

\newcommand{\commentaireligne}[1]{$\mm ---#1$}{}
\newcommand{\sepcom}{\hspace{.4em}\&\hspace{.4em}\,}

%% Autre %%
\lstset{language=C++,basicstyle=\footnotesize\ttfamily}
\newcommand{\BigO}{\mathcal{O}}





\begin{document}
\centerline{\Huge \bf Question 1}
\bigskip
\section*{Description textuelle}

L'algorithme se base sur ces observations suivantes:
\begin{enumerate}
    \item Zéro est l'élément absorbant de la multiplication;
    \item Le résultat est un produit d'éléments de vecteur (une multiplication);
    \item Lorsque deux zéro sont dans le vecteur, le produit sera toujours zéro;
    \item Nous pouvons émuler la non-production d'un élément, en divisant le produit par celui-ci, pour vu qu'il ne soit pas zéro.
\end{enumerate}

L'algorithme débute donc en initialisant une variable pour conserver le produit total (initialiser à 1), 
ainsi que deux variables "indicatices" (flags). Un pour conserver l'indice d'un élément absorbant et l'autre pour indiquer s'il y a plus d'un élément absorbant.

Puis, l'algorithme parcourt tous les éléments de notre vecteur entrant. S'il trouve pour la première fois un zéro, il affecter l'indice
où cet élément se trouve dans le vecteur. S'il en trouve un deuxième il affecte la valeur bouléen indiquant plusieurs zéros à vrai. 

Cette boucle terminée, il entre dans une des trois embranchements dépendanments de la valeur des variables indicatrices.

Premièrement, si la variable booléenne indiquant que plusieurs zéro ont été trouvés dans le vecteur entrant,
alors nous initialisons le vecteur résultat pour qu'il ne contienne que des zéros, puisque nous sommes garantis qu'il 
y aura une mutiplication par zéro pour tout ces éléments. 

Sinon, si la variable indiquant l'indice d'un zéro a été définie, alors tous les éléments du vecteur résultat seront
à zéro, à l'exception de l'élément à cet indice qui aura le résultat total du produit.

Finalement, si aucunne des deux variables indicatrices n'a été définie, alors chaque élément du vecteur résultat sera égale au produit, diviser par 
l'élément à l'indice correspondant du vecteur entrant.

\section*{Analyse de l'algorithme}

Puisque l'algorithme est trop complexe pour être analysé à l'aide d'une seule opératoire de base,
nous allons séparer l'algorithme en quatres parties et analyser chacune de ces parties individuellement,
puis conclure sur sur l'entièreté de l'algorithme à partir de ces sous-analyses.

La taille de l'instance est $n$, soit la cardinalité du vecteur entrant $A$.

\subsection*{Bloc A}

Le bloc A est composé de la première boucle \lstinline{for} et des déclarations lui précédents. 

Nous pouvons choisir comme opération de base le \lstinline{!productIsAlwaysZero}, car c'est la comparaison qui est effectué
le plus souvent, c'est-à-dire à chaque itération. De plus, la fonction \lstinline{A.at(i)} à l'intérieur de la boucle s'effectue en temps constant.


Le nombre de fois que cette opération de base peut s'exécuter dépendant du contenu du vecteur entrant ainsi que de sa cardinalité.

\subsubsection*{Meilleur cas}
En meilleur cas, les deux premiers éléments du vecteur sont 0. Si la boucle découvre deux 0, elle se courcircuite. Nous avons donc que:
\begin{deriv}
    C^A_{best}(n) = 3
    \<\Rightarrow
    \commentaire{Donc}
    1 \leq C^A_{best}(n) = 3 \leq 5
    \<\in 
    \commentaire{Définition de $\Theta$ avec $c_1 = 1$, $c_2 = 5$ et $n_0 = 0$}    
    \Theta(1)
\end{deriv}

\subsubsection*{Pire cas}
En pire cas, nous devons parcourir l'ensemble des éléments du vecteur entrant. À chacune des boucles, nous devons 
effectuer une seule comparaison, puis nous effectuons une dernière compairaison avant de sortir. Nous avons donc
\begin{deriv}
    C^A_{worst}(n) 
    \<= 
    \commentaire{Définition mathématique}
    \sum_{0}^{n-1}1 + 1
    \<=
    \commentaire{Première règle des sommations}
    (((n-1)-0+1) \times 1) + 1
    \<=
    \commentaire{Simplification}
    n + 1
    \<\Rightarrow
    \commentaire{Donc}
    \frac{1}{2}n \leq C^A_{worst}(n) = n + 1 \leq 2n $ $ {\forall n \geq 1}
    \<\in
    \commentaire{Définition de $\Theta$ avec $c_1 = \frac{1}{2}$, $c_2 = 2$ et $n_0 = 1$  }
    \Theta(n)
\end{deriv}

\subsection*{Bloc B}

Le bloc B est composé uniquement du premier bloc du \lstinline{if}, soit :

\begin{lstlisting}
    B.assign(VECTOR_SIZE, 0);
\end{lstlisting}

Ce bloc est exécuté uniquement si deux zéros sont trouvés dans le vecteur entrant.

L'opération à utiliser est donc l'appel à la fonction \lstinline{std::vector::assign}.

La complexité de la fonction \lstinline{std::vector::assign} est linéaire en tout temps sur la valeur du premier paramètre.
Dans notre cas, ce paramètre est équivalent à la cardinalité du vecteur entrant. 
Donc
\begin{deriv}
    C^B(n)
    \<=
    \commentaire{Définition de la complexité de $C^B$}
    C_{assign}(n) \cdot 1
    \<=
    \commentaire{Simplification}
    C_{assign}(n)
    \<\in
    \commentaire{Documentation de \lstinline{std::vector::assign}}
    \Theta(n)
\end{deriv}

\subsection*{Bloc C}

Le bloc C est composé uniquement du bloc \lstinline{else if}, soit:
\begin{lstlisting}
    B.assign(VECTOR_SIZE, 0);
    B.at(indexOfAbsorbingElement) = totalProductExceptZeroes;
\end{lstlisting}

Ce bloc est exécuté uniquement si un seul zéro a été trouvé dans le vecteur entrant.

L'opération à utiliser est donc l'appel à la fonction \lstinline{std::vector::assign}, puisque celle-ci à
une complexité linéaire sur la valeur du premier paramètre en tout temps, alors que la fonction \lstinline{std::vector::at}
est constante en tout temps. Donc
\begin{deriv}
    C^C(n)
    \<=
    \commentaire{Définition de la complexité de $C^C$}
    C_{assign}(n) \cdot 1
    \<=
    \commentaire{Simplification}
    C_{assign}(n)
    \<\in
    \commentaire{Documentation de \lstinline{std::vector::assign}}
    \Theta(n)
\end{deriv}

\subsection*{Bloc D}

Le bloc D est composé de la boucle \lstinline{for} situé dans le \lstinline{else}.

Ce bloc est exéctuer que lorsque aucun zéro n'a été trouvé dans le vecteur entrant.

L'opération à utiliser est l'appel à la fonction \lstinline{std::vector::push_back}, car elle a une complexité amortie 
de $\Theta(1)$ et qu'elle est appelé $n$ fois, soit à une constante près de l'élément appeler le plus souvent.
De plus, l'appel à \lstinline{std::vector::at} à une complexité constante qui est moindre ou égale à la complexité de \lstinline{std::vector::push_back}.

Donc
\begin{deriv}
    C^D(n)
    \<=
    \commentaire{Définition de la complexité de $C^D$}
    \sum_{i=0}^{n} C_{push\_back}(n)
    \<=
    \commentaire{Première règle de somation}
    ((n-1) - 0 + 1) \cdot C_{push\_back}(n)
    \<=
    \commentaire{Simplification }
    n \cdot C_{push\_back}(n)
    \<\approx
    \commentaire{Abus de notation. 
    \\Définition de la complexité de \lstinline{std::vector::push_back} }
    n \cdot 1
    \<=
    \commentaire{Simplification }
    n
    \<\Rightarrow
    \commentaire{Donc}
    n \leq C^D(n) = n \leq n $ $ {\forall n \geq 0}
    \<\in
    \commentaire{Définition de $\Theta$ avec $c_1 = c_2 = 1$ et $n_0 = 0$}
    \Theta(n)
\end{deriv}

\subsection*{Résultat final}

L'algorithme est composé de 4 blocs. Dont un et un seul bloc entre B, C et D ne peut-être exécuter.
Notons $C(n)$ le temps d'exécution de l'algorithme complet. 
Le bloc A est exécuté dans tous les cas. 

En meilleur cas, le bloc B est executé après le bloc A. Nous avons donc :

\begin{deriv}
    C_{best}(n)
    \<=
    \commentaire{Définition de la complexité de $C_best$}
    C^A_{best}(n) + C^B(n)
    \<=
    \commentaire{Définition de $C^A_{best}(n)$ et $C^B(n)$}
    3 + C_{assign}(n)
    \<\approx
    \commentaire{Abus de notation. 
    \\Définition de la complexité de \lstinline{std::vector::assign}}
    3 + n
    \<=
    \commentaire{Par la règle du maximum}
    n
    \<\Rightarrow
    \commentaire{Donc}
    n \leq C_{best}(n) = n \leq n $ $ \forall n \geq 0
    \<\in
    \commentaire{Définition de $\Theta$ avec $c_1 = c_2 = 1$ et $n_0 = 0$  }
    \Theta(n)
\end{deriv}

Dans le pire cas, le bloc C ou D est exécuté après le bloc A. Nous avons donc:
\begin{deriv}
    C_{worst_C}(n)
    \<=
    \commentaire{Définition de la complexité de $C_{worst_C}$}
    C^A_{worst}(n) + C^C(n)
    \<=
    \commentaire{Définition de $C^A_{best}(n)$ et $C^C(n)$}
    n + 1 + C_{assign}(n)
    \<\approx
    \commentaire{Abus de notation. 
    \\Définition de la complexité de \lstinline{std::vector::assign}}
    n + 1 + n
    \<=
    \commentaire{Simplification}
    2n+1
    \<=
    \commentaire{Par la règle du maximum}
    2n
    \<\Rightarrow
    \commentaire{Donc}
    n \leq C_{worst_C}(n) = 2n \leq 2n $ $ \forall n \geq 0
    \<\in
    \commentaire{Définition de $\Theta$ avec $c_1 = 1$, $c_2 = 2$ et $n_0 = 0$  }
    \Theta(n)
\end{deriv}

et aussi que:
\begin{deriv}
    C_{worst_D}(n)
    \<=
    \commentaire{Définition de la complexité de $C_{worst_D}$}
    C^A_{worst}(n) + C^D(n)
    \<=
    \commentaire{Définition de $C^A_{best}(n)$ et $C^D(n)$}
    n + 1 + n
    \<=
    \commentaire{Simplification}
    2n+1
    \<=
    \commentaire{Par la règle du maximum}
    2n
    \<\Rightarrow
    \commentaire{Donc}
    n \leq C_{worst_D}(n) = 2n \leq 2n $ $ \forall n \geq 0
    \<\in
    \commentaire{Définition de $\Theta$ avec $c_1 = 1$, $c_2 = 2$ et $n_0 = 0$  }
    \Theta(n)
\end{deriv}

Donc, nous avons que cet algorithme est linéaire sur la cardinalité du vecteur entrant pour tous les cas.

\end{document} 